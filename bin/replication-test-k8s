#!/bin/bash

# USAGE
#
# This restores a Leader from backup, deploys and configures a number of K8S
# Followers, and runs a series of tests to verify that replication is working
# as expected. It also monitors the host for system resource utilization,
# the container logs, and outputs them into a single tarball.
#
# ./bin/replication-test-k8s
#
# Patch release: 13.3.2
# VERSION=5.17.4-16 K8S_FOLLOWER_TAG=2.3.5-12 FOLLOWER_COUNT=2 ./bin/replication-test-k8s
#
# Production release: 13.3.0
# VERSION=13.3.0 K8S_FOLLOWER_TAG=2.3.4-6 FOLLOWER_COUNT=2 ./bin/replication-test-k8s
#
# Useful for when only testing changes to tests or the test harness itself:
# USE_EXISTING_ENVIRONMENT=true ./bin/replication-test-k8s
#

# Always work from repo root directory
cd "$(dirname ${0})/..";

source ./bin/functions
source ./bin/utils.sh

LOG_DIR="$(k8s_log_dir)"
LEADER_LOG_DIR="$(k8s_log_dir)/logs/leader"
FOLLOWER_LOG_DIR="$(k8s_resources_log_dir)"
RESOURCE_UTLIZATION_LOG_DIR="$LOG_DIR/resources"
TOP_LOG_DIR="$RESOURCE_UTLIZATION_LOG_DIR/top"
DOCKER_STATS_LOG_DIR="$RESOURCE_UTLIZATION_LOG_DIR/docker_stats"
REPLICATION_LOG_STATS_DIR="$LOG_DIR/replication"
PG_ID_LOG_DIR="$LOG_DIR/pg_identifier"
ARCHIVE_DIR="tmp/artifacts"

USE_EXISTING_ENVIRONMENT="${USE_EXISTING_ENVIRONMENT:-false}"
K8S_FOLLOWER_TAG="${K8S_FOLLOWER_TAG:-edge}"
VERSION="${VERSION:-5.0-stable}"
FOLLOWER_COUNT="${FOLLOWER_COUNT:-2}"
POLICY_COUNT="${REPLICATION_POLICY_COUNT:-2}"
SECRET_COUNT="${REPLICATION_SECRET_COUNT:-2}"
RESOURCE_INTERVAL="${RESOURCE_INTERVAL:-60}"
MAX_ATTEMPTS="${MAX_ATTEMPTS:-10}"
# The timeout in seconds to wait for the all Followers to be deployed
# 10 Minute Default
CONFIGURE_FOLLOWER_TIMEOUT=${CONFIGURE_FOLLOWER_TIMEOUT:-600}

# Use this to hide WARN from docker compose...
# WARN[0000] The "VERSION" variable is not set. Defaulting to a blank string. 
export VERSION

RESOURCE_MONITOR_PID=""

# Initialize two indexed arrays to hold the test command names and their
# exit codes
TEST_COMMANDS=()
EXIT_CODES_FIRST_RUN=()
EXIT_CODES_SECOND_RUN=()

finish() {
  # Re-enable exit on error, in case any of these commands fail.
  set -e
  exit_code=$1

  # If a background process PID was stored, kill it (do not fail script if it is not found)
  if [ -n "$RESOURCE_MONITOR_PID" ]; then
    echo "Killing resource monitor: $RESOURCE_MONITOR_PID..."
    kill -9 "$RESOURCE_MONITOR_PID" || true
  fi

  ./bin/create-log-artifacts --log-directory "$LOG_DIR" --follower-count  "${FOLLOWER_COUNT}"
  print_test_suite_summary

  teardown_compose_environment
  determine_exit_code "$exit_code"
  exit $?
}

main(){
  # We want to exit immediately if any setup command fails. This will be
  # disabled when the tests start running, as we want to run all tests.
  set -e

  # Define test suite(s) commands
  TEST_COMMANDS+=("./bin/test-k8s-follower-pg-identifier")
  TEST_COMMANDS+=("./bin/dump-k8s-follower-info --follower-count \"${FOLLOWER_COUNT}\"")
  TEST_COMMANDS+=("./bin/test-secret-replication-k8s --max-attempts \"${MAX_ATTEMPTS}\" --policy-count \"${POLICY_COUNT}\" --secret-count \"${SECRET_COUNT}\" --follower-count \"${FOLLOWER_COUNT}\"")
  TEST_COMMANDS+=("./bin/test-table-rows-match-k8s --follower-count \"${FOLLOWER_COUNT}\" --max-attempts \"${MAX_ATTEMPTS}\"")
  TEST_COMMANDS+=("./bin/test-leader-logs-for-replication-slot-errors --log-directory \"$LEADER_LOG_DIR\"")
  TEST_COMMANDS+=("./bin/test-k8s-follower-logs-for-replication-slot-errors --log-directory \"$FOLLOWER_LOG_DIR\"")

  trap 'finish $?' EXIT

  if [ "$USE_EXISTING_ENVIRONMENT" = "true" ]; then
    echo "USE_EXISTING_ENVIRONMENT is set to '$USE_EXISTING_ENVIRONMENT'... Setting RESOURCE_INTERVAL to '1'..."
    RESOURCE_INTERVAL="1"
  fi

  if ! command -v timeout >/dev/null 2>&1; then
    echo "FATAL: the timeout command is not available which is a requirement for this script."
    exit 1
  fi

  echo "Running replication tests with '${FOLLOWER_COUNT}' K8S Follower(s) version '${K8S_FOLLOWER_TAG}'  on with Leader Appliance Version '${VERSION}'..."

  echo "Removing old logs from: $LOG_DIR"
  rm -rf "$LOG_DIR"

  mkdir -p "$LOG_DIR"
  mkdir -p "$ARCHIVE_DIR"
  mkdir -p "$TOP_LOG_DIR"
  mkdir -p "$DOCKER_STATS_LOG_DIR"
  mkdir -p "$PG_ID_LOG_DIR"

  teardown_compose_environment

  # Exclude the grep command and the current process
  echo "Listening for orphaned resource monitoring processes from this script..."
  echo "WARNING: anything is listening below, we'll want to kill those!"
  ps -a | grep "$0" | grep -v "grep" | grep -v "$$" || true
  echo "Done listening."

  # Deploy the Leader (including loadbalancer)
  deploy_and_restore_leader

  record_resource_utilization &
  RESOURCE_MONITOR_PID=$!
  echo "Starting resource monitor: $RESOURCE_MONITOR_PID"

  echo "Provisioning K8S Follower(s) using tag: '${K8S_FOLLOWER_TAG}'..."
  echo "If any one Follower takes longer than $CONFIGURE_FOLLOWER_TIMEOUT seconds to configure, the configuration process for all Followers will be stopped."
  deploy_k8s_followers

  # This is a Developer Exprience option for using USE_EXISTING_ENVIRONMENT
  if [ "$USE_EXISTING_ENVIRONMENT" = "true" ]; then
    local interval=10
    echo "USE_EXISTING_ENVIRONMENT is set to '$USE_EXISTING_ENVIRONMENT'... Sleeping for '$interval' seconds to let the resource monitor get some ticks in..."
    echo "Press any key to proceed immediately, or wait '$interval' seconds to proceed automatically."
    if ! read -t "$interval" -s; then
      echo "Proceeding..."
    fi
  fi

  # Logs are a prerequisite for log scanning tests(s)...
  # A failure to log wil cause that test to fail, but we continue to run tests
  # in effort to get as much information from a long running pipeline as
  # possible.
  announce "Dumping Appliance and K8S Resource Logs..."
  echo "This is required for the test that checks K8S Follower logs for replication slot errors..."
  ./bin/dump-leader-logs --no-fail --log-directory "$LEADER_LOG_DIR"
  ./bin/dump-k8s-resource-logs "$FOLLOWER_LOG_DIR" "$(_get_k8s_follower_namespace)" "$(_get_k8s_operator_namespace)" || true

  # Run all test suite commands and capture their exit codes. Any failure
  # does not prevent the following tests from running.
  set +e
  announce "BEGIN TEST SUITE - BEFORE FAILOVER"
  for i in "${!TEST_COMMANDS[@]}"; do
    announce "BEGIN TEST: ${TEST_COMMANDS[$i]}"
    # shellcheck disable=SC2086
    eval ${TEST_COMMANDS[$i]}
    # shellcheck disable=SC2004
    EXIT_CODES_FIRST_RUN[$i]=$?
  done

  echo "Triggering a Leader failover..."
  perform_failover
  echo "Active Leader container is: $(discover_leader_container)"

  # Wait 5 minutes for all Followers to begin rebasing
  echo "Waiting 5 minutes for Follower(s) to begin rebasing..."
  sleep 300

  echo "Waiting for Follower(s) to become healthy after rebasing..."
  wait_for_followers

  announce "BEGIN TEST SUITE - AFTER FAILOVER"
  for i in "${!TEST_COMMANDS[@]}"; do
    announce "BEGIN TEST: ${TEST_COMMANDS[$i]}"
    # shellcheck disable=SC2086
    eval ${TEST_COMMANDS[$i]}
    # shellcheck disable=SC2004
    EXIT_CODES_SECOND_RUN[$i]=$?
  done

  echo "Tests are finished executing!"
  echo "DONE."
}

teardown_compose_environment() {
  if [ "$USE_EXISTING_ENVIRONMENT" = "true" ]; then
    echo "USE_EXISTING_ENVIRONMENT is set to '$USE_EXISTING_ENVIRONMENT', skipping teardown of the Compose environment..."
    return
  fi
  ./bin/dap --stop || true
}

deploy_and_restore_leader() {
  if [ "$USE_EXISTING_ENVIRONMENT" = "true" ]; then
    echo "USE_EXISTING_ENVIRONMENT is set to '$USE_EXISTING_ENVIRONMENT', skipping deployment and restoration of Leader..."
    return
  fi

  echo "Deploying the Leader using tag: '${VERSION}'..."
  bin/dap --provision-master --version "$VERSION"

  # The most recent backup is used from system/backup
  echo "Restoring the Leader from backup using tag: '${VERSION}'..."
  bin/dap --restore-from-backup --version "$VERSION"

  echo "Importing certificates..."
  bin/dap --import-custom-certificates --version "$VERSION"
  bin/dap --wait-for-master

  echo "Deploying the Standbys..."
  bin/dap --provision-standbys --version "$VERSION"
  bin/dap --wait-for-master

  echo "Enabling auto-failover..."
  bin/dap --enable-auto-failover --auto-failover-ttl 60

  echo "Waiting for healthy cluster..."
  bin/dap --wait-for-master
}

deploy_k8s_followers() {
  if [ "$USE_EXISTING_ENVIRONMENT" = "true" ]; then
    echo "USE_EXISTING_ENVIRONMENT is set to '$USE_EXISTING_ENVIRONMENT', skipping deployment of Followers..."
    return
  fi

  # The following enables us to kill long-running configurations (hanging).
  # This allows the pipeline to continue, fail, and for artifacts to still be
  # generated.
  set +e
  echo "Will wait for ${CONFIGURE_FOLLOWER_TIMEOUT} seconds for the KinD Cluster and K8S Followers to be created..."
  { timeout --foreground "$CONFIGURE_FOLLOWER_TIMEOUT" ./bin/dap --provision-k8s-follower --k8s-follower-version "${K8S_FOLLOWER_TAG}" --follower-count "${FOLLOWER_COUNT}" --k8s-follower-conjur-log-level debug --k8s-follower-timeout "${CONFIGURE_FOLLOWER_TIMEOUT}"; exit_status="$?"; }
  set -e

  if [ $exit_status -eq 124 ]; then
    echo "FATAL: Timeout of '$CONFIGURE_FOLLOWER_TIMEOUT' exceeded when provisioning K8S Follower(s)!"
    exit 1
  elif [ $exit_status -eq 0 ]; then
    echo "SUCCESS: K8S Follower(s) were succesfully configured completed before timeout!"
  else
    echo "FATAL: Failed to configure K8S Follower(s) with error: $exit_status"
    exit 1
  fi
}

perform_failover() {
  if [ "$USE_EXISTING_ENVIRONMENT" = "true" ]; then
    echo "USE_EXISTING_ENVIRONMENT is set to '$USE_EXISTING_ENVIRONMENT', skipping triggering auto-failover..."
    return
  fi

  # Trigger a failover and wait for the cluster to become healthy again
  bin/dap --trigger-failover
  sleep 5
  bin/dap --wait-for-master
}

wait_for_followers() {
  for ((i=1; i<=FOLLOWER_COUNT; i++))
  do
    echo "Waiting for Follower conjur-follower-${i}.mycompany.local to be healthy..."
    wait_for_follower "conjur-follower-${i}.mycompany.local"
  done
}

wait_for_follower() {
  local follower_hostname=$1
  local container_id
  local attempts=0
  local max_attempts=180

  container_id=$(docker compose ps -q $follower_hostname)
  if [ -z "$container_id" ]; then
    echo "WARNING: No container ID found for service '$follower_hostname' (it is not running), skipping!"
    return
  fi

  while true; do
    attempts=$((attempts + 1))
    if [ $attempts -gt $max_attempts ]; then
      echo "FATAL: Follower '$follower_hostname' did not become healthy after '$max_attempts' attempts!"
      exit 1
    fi

    echo "Checking Follower '$follower_hostname' health status (attempt $attempts/$max_attempts)..."
    if docker compose exec "$follower_hostname" curl -k --fail-with-body https://localhost/health &>/dev/null; then
      echo "Follower '$follower_hostname' is healthy!"
      break
    fi

    echo "Follower '$follower_hostname' is not healthy yet, waiting 10 seconds before trying again..."
    sleep 10
  done

}

# IMPORTANT: this is all done in sequence, each statistic is not a separate
# process!
record_resource_utilization() {
  while true; do
    snapshot_top > /dev/null 2>&1 || true
    snapshot_docker_stats > /dev/null 2>&1 || true
    set -x
    snapshot_leader_replication_status > /dev/null 2>&1 || true
    snapshot_follower_replication_status > /dev/null 2>&1 || true
    snapshot_leader_pg_identifier > /dev/null 2>&1 || true
    sleep "$RESOURCE_INTERVAL"
  done
}

snapshot_top() {
  timestamp=$(utc_timestamp)
  xtop > "$TOP_LOG_DIR/$timestamp.log"
}

snapshot_docker_stats() {
  timestamp=$(utc_timestamp)
  docker stats --no-stream > "$DOCKER_STATS_LOG_DIR/$timestamp.log"
}

# Print information of the replication status of the Leader
snapshot_leader_replication_status() {
  local log_dir
  local docker_leader_container

  docker_leader_container=$(discover_leader_container)

  timestamp=$(utc_timestamp)
  log_dir="$REPLICATION_LOG_STATS_DIR/leader/$docker_leader_container"
  pg_stat_replication_log_dir="$log_dir/pg_stat_replication"
  pg_stat_replication_log_dir_log_file="$pg_stat_replication_log_dir/$timestamp.log"
  pg_stat_activity_log_dir="$log_dir/pg_stat_activity"
  pg_stat_activity_log_dir_log_file="$pg_stat_activity_log_dir/$timestamp.log"

  mkdir -p "$pg_stat_replication_log_dir"
  mkdir -p "$pg_stat_activity_log_dir"

  docker compose exec -T "$docker_leader_container" bash -c $"
        chpst -u conjur psql -c \"\\copy (SELECT * from pg_stat_replication) To '/tmp/output.csv' With CSV HEADER\"
      " || true
  docker compose exec "$docker_leader_container" bash -c "cat /tmp/output.csv" | tee "$pg_stat_replication_log_dir_log_file" || true

  docker compose exec -T "$docker_leader_container" bash -c $"
        chpst -u conjur psql -c \"\\copy (SELECT * from pg_stat_activity) To '/tmp/output.csv' With CSV HEADER\"
      " || true
  docker compose exec "$docker_leader_container" bash -c "cat /tmp/output.csv" | tee "$pg_stat_activity_log_dir_log_file" || true
}

# Print information of the replication status of each Follower
# WARNING: at scale, this will output a lot of files
snapshot_follower_replication_status() {
  local running_pods
  local table_names

  running_pods=$(get_k8s_follower_pod_names)
  table_names=("pg_stat_subscription" "pg_subscription_rel" "pg_subscription")

  for pod in $running_pods; do
    local log_dir

    log_dir="$REPLICATION_LOG_STATS_DIR/follower/$pod"

    for i in "${!table_names[@]}"; do
      local timestamp
      local table_log_dir

      timestamp=$(utc_timestamp)
      table=${table_names[$i]}
      table_log_dir="$log_dir/$table"

      mkdir -p "$table_log_dir"

      bin/kubectl exec -n "$(_get_k8s_follower_namespace)" "$pod" -c postgres -- pg-uid-wrapper "psql --username=postgres --host=/tmp --dbname=conjur --command='\copy (SELECT * from $table) To '/tmp/$table.csv' With CSV HEADER;'" || true
      bin/kubectl "exec $pod -n '$(_get_k8s_follower_namespace)' -c postgres -- bash -c 'cat /tmp/$table.csv'" > "$table_log_dir/${timestamp}.log" || true
    done
  done
}

snapshot_leader_pg_identifier() {
  local log_dir
  local docker_leader_container

  docker_leader_container=$(discover_leader_container)

  timestamp=$(utc_timestamp)
  log_dir="$PG_ID_LOG_DIR/leader/$docker_leader_container"

  mkdir -p "$log_dir"

  pgid=$(docker compose exec -T "$docker_leader_container" chpst -u postgres psql -tqc 'SELECT system_identifier FROM pg_control_system();')
  echo "Got pg identifer for Leader '$docker_leader_container': $pgid"
  echo "$pgid" > "$log_dir/$timestamp.log" || true
}

xtop() {
  if [ "$(uname)" = "Darwin" ]; then
      # macOS
      top -l 1 -n 30 -o cpu -o mem
  else
      # Linux
      top -b -n 1 | head -n 30
  fi
}

print_test_suite_summary() {
  announce "TEST SUITE SUMMARY"
  
  for i in "${!TEST_COMMANDS[@]}"; do
    echo "Command: ${TEST_COMMANDS[$i]}"
    echo "Exit code before failover: ${EXIT_CODES_FIRST_RUN[$i]}"
    echo "Exit code after failover: ${EXIT_CODES_SECOND_RUN[$i]}"
  done
}

determine_exit_code() {
  if [ "$1" -ne 0 ]; then
    echo "Setup failed with exit code: $exit_code"
    return 1
  fi

  for exit_code in "${EXIT_CODES_FIRST_RUN[@]}"; do
    if [ "$exit_code" -ne 0 ]; then
      echo "A test failed with exit code: $exit_code"
      return 1
    fi
  done

  for exit_code in "${EXIT_CODES_SECOND_RUN[@]}"; do
    if [ "$exit_code" -ne 0 ]; then
      echo "A test failed with exit code: $exit_code"
      return 1
    fi
  done

  return 0
}

main "$@"
